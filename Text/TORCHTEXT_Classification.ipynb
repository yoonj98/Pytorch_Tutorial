{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TORCHTEXT_Classification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPtU2JBY+GM05upAXazIorQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[""],"metadata":{"id":"9cMb7QGc4KTo"}},{"cell_type":"markdown","source":["  * 반복자(iterator)로 가공되지 않은 데이터(raw data)에 접근하기  \n","  * 가공되지 않은 텍스트 문장들을 모델 학습에 사용할 수 있는 torch.Tensor 로 변환하는 데이터 처리 파이프라인 만들기  \n","  * torch.utils.data.DataLoader 를 사용하여 데이터를 섞고 반복하기(shuffle and iterate)"],"metadata":{"id":"YmIuep2m4LPQ"}},{"cell_type":"markdown","source":["### Data "],"metadata":{"id":"iAsxDclU48zJ"}},{"cell_type":"markdown","source":["#### 1. raw data iterator"],"metadata":{"id":"674LF2j84Rm2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOViiWDb4EuF"},"outputs":[],"source":["import torch\n","from torchtext.datasets import AG_NEWS\n","train_iter = AG_NEWS(split='train')  # AG_NEWS 데이터셋 반복자는 레이블(label)과 문장의 튜플(tuple) 형태로 가공되지 않은 데이터"]},{"cell_type":"markdown","source":["#### 2. Data Preprocessing pipeline"],"metadata":{"id":"iqKavZa74cRl"}},{"cell_type":"code","source":["# 가공되지 않은 학습 데이터셋으로 어휘집을 만들기\n","\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","tokenizer = get_tokenizer('basic_english')\n","train_iter = AG_NEWS(split='train')\n","\n","def yield_tokens(data_iter):\n","    for _, text in data_iter:\n","        yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])\n","\n","print(vocab(['here', 'is', 'an', 'example']))\n","\n","text_pipeline = lambda x: vocab(tokenizer(x))\n","label_pipeline = lambda x: int(x) - 1\n","\n","print(label_pipeline('10'))"],"metadata":{"id":"dmVDb4gv4gbA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. data batch and iterator"],"metadata":{"id":"FUIAoNid4vsk"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","    for (_label, _text) in batch:\n","         label_list.append(label_pipeline(_label))\n","         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","         text_list.append(processed_text)\n","         offsets.append(processed_text.size(0))\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return label_list.to(device), text_list.to(device), offsets.to(device)\n","\n","train_iter = AG_NEWS(split='train')\n","dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"],"metadata":{"id":"gces8_yt43V1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model"],"metadata":{"id":"uOYDY6Rf4-_l"}},{"cell_type":"code","source":["from torch import nn\n","\n","class TextClassificationModel(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super(TextClassificationModel, self).__init__()\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","        embedded = self.embedding(text, offsets)\n","        return self.fc(embedded)"],"metadata":{"id":"X3AZNPm65AD9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Generate Instance\n","AG_NEWS Data's Class  \n","1 : World (세계)  \n","2 : Sports (스포츠)  \n","3 : Business (경제)  \n","4 : Sci/Tec (과학/기술)"],"metadata":{"id":"uLX1Slyp5B4K"}},{"cell_type":"code","source":["# 어휘집의 크기(Vocab size)는 어휘집(vocab)의 길이와 같습니다. 클래스의 개수는 레이블의 개수와 같음\n","\n","train_iter = AG_NEWS(split='train')\n","num_class = len(set([label for (label, text) in train_iter]))\n","vocab_size = len(vocab)\n","emsize = 64\n","model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"],"metadata":{"id":"m1oz0wvG5L6P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Train and Evaluate"],"metadata":{"id":"59oxb7TA5QiX"}},{"cell_type":"code","source":["import time\n","\n","def train(dataloader):\n","    model.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 500\n","    start_time = time.time()\n","    for idx, (label, text, offsets) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        predicted_label = model(text, offsets)\n","        loss = criterion(predicted_label, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","        optimizer.step()\n","        total_acc += (predicted_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","        if idx % log_interval == 0 and idx > 0:\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:5d}/{:5d} batches '\n","                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n","                                              total_acc/total_count))\n","            total_acc, total_count = 0, 0\n","            start_time = time.time()\n","\n","def evaluate(dataloader):\n","    model.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predicted_label = model(text, offsets)\n","            loss = criterion(predicted_label, label)\n","            total_acc += (predicted_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc/total_count"],"metadata":{"id":"Y5CAXehp5Vjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","\n","# Hyperparameters\n","EPOCHS = 10 # epoch\n","LR = 5  # learning rate\n","BATCH_SIZE = 64 # batch size for training\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","total_accu = None\n","train_iter, test_iter = AG_NEWS()\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","num_train = int(len(train_dataset) * 0.95)\n","split_train_, split_valid_ = \\\n","    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n","\n","train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n","                              shuffle=True, collate_fn=collate_batch)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                             shuffle=True, collate_fn=collate_batch)\n","\n","for epoch in range(1, EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader)\n","    accu_val = evaluate(valid_dataloader)\n","    if total_accu is not None and total_accu > accu_val:\n","      scheduler.step()\n","    else:\n","       total_accu = accu_val\n","    print('-' * 59)\n","    print('| end of epoch {:3d} | time: {:5.2f}s | '\n","          'valid accuracy {:8.3f} '.format(epoch,\n","                                           time.time() - epoch_start_time,\n","                                           accu_val))\n","    print('-' * 59)"],"metadata":{"id":"cXnpGmH85Wbj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Checking the results of test dataset.')\n","accu_test = evaluate(test_dataloader)\n","print('test accuracy {:8.3f}'.format(accu_test))"],"metadata":{"id":"dEmtd4rI5az-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ag_news_label = {1: \"World\",\n","                 2: \"Sports\",\n","                 3: \"Business\",\n","                 4: \"Sci/Tec\"}\n","\n","def predict(text, text_pipeline):\n","    with torch.no_grad():\n","        text = torch.tensor(text_pipeline(text))\n","        output = model(text, torch.tensor([0]))\n","        return output.argmax(1).item() + 1\n","\n","ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n","    enduring the season’s worst weather conditions on Sunday at The \\\n","    Open on his way to a closing 75 at Royal Portrush, which \\\n","    considering the wind and the rain was a respectable showing. \\\n","    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n","    was another story. With temperatures in the mid-80s and hardly any \\\n","    wind, the Spaniard was 13 strokes better in a flawless round. \\\n","    Thanks to his best putting performance on the PGA Tour, Rahm \\\n","    finished with an 8-under 62 for a three-stroke lead, which \\\n","    was even more impressive considering he’d never played the \\\n","    front nine at TPC Southwind.\"\n","\n","model = model.to(\"cpu\")\n","\n","print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"],"metadata":{"id":"is_x78e45b8Q"},"execution_count":null,"outputs":[]}]}